# general
exp_name: mlp_example
run_name: run1
max_epoch: 10
log_every_n_steps: 1
gradient_clipping: 0
accumulate_grad_batches: 1  # make this number of forward passes before doing a backprop step

# set to null to avoid setting a seed (can speed up GPU computation, but
# results will not be reproducible)
seed: 1234

elements: ["Si"]

# data
data:
  batch_size: 1024
  num_workers: 0
  max_atom: 8
  use_fixed_lattice_parameters: False
  noise:
    total_time_steps: 100
    sigma_min: 0.0001
    sigma_max: 0.25

# architecture
spatial_dimension: 3
model:
  loss: # Only the relative coordinates loss will matter.
    coordinates:
      algorithm: mse
      lambda_weight: 1.0
    atom_types:
      algorithm: d3pm
      lambda_weight: 0.0
      ce_weight: 1.0
    lattice_parameters:
      algorithm: mse
      lambda_weight: 0.0
  score_network:
    architecture: mlp
    use_permutation_invariance: False
    spatial_dimension: 1
    number_of_atoms: 2
    num_atom_types: 1
    n_hidden_dimensions: 3
    hidden_dimensions_size: 64
    relative_coordinates_embedding_dimensions_size: 32
    noise_embedding_dimensions_size: 16
    time_embedding_dimensions_size: 16
    atom_type_embedding_dimensions_size: 1
    condition_embedding_size: 64
    lattice_parameters_embedding_dimensions_size: 1

# Sampling from the generative model
diffusion_sampling:
  noise:
    total_time_steps: 10
    sigma_min: 0.0001  
    sigma_max: 0.1 
  sampling:
    algorithm: predictor_corrector
    num_atom_types: 1
    spatial_dimension: 3
    number_of_atoms: 8
    number_of_samples: 16
    sample_batchsize: 16
    record_samples: True
    cell_dimensions: [5.43, 5.43, 5.43]
  metrics:
    compute_energies: True
    compute_structure_factor: True
    structure_factor_max_distance: 5.0  


sampling_visualization:
  record_every_n_epochs:  1
  first_record_epoch: 0
  record_trajectories: True
  record_energies: True
  record_structure: True

# optimizer and scheduler
optimizer:
  name: adamw
  learning_rate: 0.001
  weight_decay: 1.0e-6

scheduler:
  name: ReduceLROnPlateau
  factor: 0.1
  patience: 3

# early stopping
early_stopping:
  metric: validation_epoch_loss
  mode: min
  patience: 10

model_checkpoint:
  monitor: validation_epoch_loss
  mode: min

# A callback to check the loss vs. sigma
loss_monitoring: 
  number_of_bins: 50
  sample_every_n_epochs: 25

oracle:
  name: lammps
  sw_coeff_filename: Si.sw


logging:
#  - comet
- tensorboard
#- csv
