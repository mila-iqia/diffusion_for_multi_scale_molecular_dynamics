"""Energy consistency analysis.

The goal of this script is to confirm that the energies generated by
LAMMPS through the Oracle (ie, what is called during sampling) is exactly
the same as the energies produced by LAMMPS during dataset generation.
This is to ensure that the configurations are exactly equivalent between
these two distinct ways of calling LAMMPS.
"""

import logging
import tempfile

import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm

from diffusion_for_multi_scale_molecular_dynamics import DATA_DIR
from diffusion_for_multi_scale_molecular_dynamics.analysis import (
    PLEASANT_FIG_SIZE, PLOT_STYLE_PATH)
from diffusion_for_multi_scale_molecular_dynamics.callbacks.sampling_visualization_callback import \
    SamplingVisualizationCallback
from diffusion_for_multi_scale_molecular_dynamics.data.diffusion.lammps_for_diffusion_data_module import (
    LammpsForDiffusionDataModule, LammpsLoaderParameters)
from diffusion_for_multi_scale_molecular_dynamics.oracle.lammps import \
    get_energy_and_forces_from_lammps
from diffusion_for_multi_scale_molecular_dynamics.utils.logging_utils import \
    setup_analysis_logger
from experiments import EXPERIMENT_ANALYSIS_DIR
from experiments.analysis_utils import get_thermo_dataset

plt.style.use(PLOT_STYLE_PATH)

logger = logging.getLogger(__name__)
dataset_name = "si_diffusion_1x1x1"

lammps_run_dir = str(DATA_DIR / dataset_name)
processed_dataset_dir = str(DATA_DIR / dataset_name / "processed")

cache_dir = str(EXPERIMENT_ANALYSIS_DIR / "cache" / dataset_name)

data_params = LammpsLoaderParameters(batch_size=64, max_atom=8)

sample_size = 1000

if __name__ == "__main__":
    setup_analysis_logger()

    logging.info(f"Starting {dataset_name} analysis")

    train_df, valid_df = get_thermo_dataset(dataset_name)

    datamodule = LammpsForDiffusionDataModule(
        lammps_run_dir=lammps_run_dir,
        processed_dataset_dir=processed_dataset_dir,
        hyper_params=data_params,
        working_cache_dir=cache_dir,
    )

    datamodule.setup()

    train_dataset = datamodule.train_dataset

    data = train_dataset[0]
    box = np.diag(data["box"].cpu().numpy())
    atom_types = data["type"].cpu().numpy()

    list_relative_positions = (
        train_dataset[:sample_size]["relative_positions"].cpu().numpy()
    )
    list_positions = train_dataset[:sample_size]["position"].cpu().numpy()

    list_positions_translated_back_in_box = list_positions % box[0, 0]

    list_expected_positions = np.dot(list_relative_positions, box)

    list_dataset_potential_energies = train_df["potential_energy"][:sample_size].values

    logger.info("Compute energy from Oracle")

    list_oracle_energies = []
    with tempfile.TemporaryDirectory() as tmp_work_dir:
        for positions in tqdm(list_positions_translated_back_in_box, "LAMMPS energies"):
            energy, forces = get_energy_and_forces_from_lammps(
                positions, box, atom_types, tmp_work_dir=tmp_work_dir
            )
            list_oracle_energies.append(energy)

    list_oracle_energies = np.array(list_oracle_energies)

    fig = SamplingVisualizationCallback._plot_energy_histogram(
        list_oracle_energies, list_dataset_potential_energies
    )
    plt.show()

    fig2 = plt.figure(figsize=PLEASANT_FIG_SIZE)
    ax2 = fig2.add_subplot(111)

    errors = list_oracle_energies - list_dataset_potential_energies

    fig2.suptitle("Error Distribution between Dataset and Oracle")
    ax2.hist(
        errors, density=True, bins=20, histtype="stepfilled", alpha=0.25, color="red"
    )
    ax2.set_xlabel("Energy (eV)")
    ax2.set_ylabel("Density")
    fig2.tight_layout()
    plt.show()
