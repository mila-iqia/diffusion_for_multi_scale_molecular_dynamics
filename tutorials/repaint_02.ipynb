{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be435dfa9f025792",
   "metadata": {},
   "source": [
    "# Repaint: A Tutorial\n",
    "\n",
    "This notebook introduces inpainting for a simple problem in 2 dimensions. We will use an \"analytical model\" that requires no\n",
    "training. This analytical model is not appropriate for a general system: it is only useful for demonstration purposes. \n",
    "Since there is no training, no actual dataset is needed: the analytical model relies on the assumption that the dataset is normal-distributed. Thus, in what follows, we will speak of the \"effective\" dataset even if it is never instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23b11b-ab2b-4de6-98c1-06f0e83ea76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where artifacts will be written. Delete it if it exists to start clean.\n",
    "import shutil\n",
    "from diffusion_for_multi_scale_molecular_dynamics import TOP_DIR\n",
    "\n",
    "output_path = TOP_DIR / \"tutorials\" / \"output\" / \"tutorial_repaint\"\n",
    "shutil.rmtree(output_path)\n",
    "\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472778f454e0515c",
   "metadata": {},
   "source": [
    "# The effective dataset\n",
    "\n",
    "We will consider a regular 2D grid as the equilibrium positions. The effective dataset will be distributed like a simple isotropic Gaussian\n",
    "centered on this 2D grid with an effective width sigma_d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945d1e7b49e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and defining global variables\n",
    "import torch\n",
    "\n",
    "from diffusion_for_multi_scale_molecular_dynamics.noise_schedulers.noise_parameters import NoiseParameters\n",
    "from utilities import get_2d_grid_equilibrium_relative_coordinates\n",
    "\n",
    "# Define the regular grid that represents the equilibrium relative coordinates\n",
    "n = 4\n",
    "\n",
    "# Define the Gaussian width of the effective dataset.\n",
    "sigma_d = 0.02\n",
    "\n",
    "equilibrium_relative_coordinates = get_2d_grid_equilibrium_relative_coordinates(n=n)\n",
    "mu = torch.tensor(equilibrium_relative_coordinates)\n",
    "\n",
    "number_of_atoms = len(equilibrium_relative_coordinates)\n",
    "spatial_dimension = 2\n",
    "elements = [\"X\"] # Just a dummy name.\n",
    "\n",
    "\n",
    "# Define the repaint constraint for the 4 atoms in the center of the grid. The constraint will\n",
    "# be a 90 degrees rotation of these points about the center of the unit cell.\n",
    "mask_grid = torch.zeros([n, n], dtype=torch.bool)\n",
    "mid = n // 2\n",
    "mask_grid[mid - 1: mid + 1, mid - 1: mid + 1] = True\n",
    "constrained_indices = torch.arange(n**2)[mask_grid.flatten()]\n",
    "\n",
    "theta = torch.tensor(torch.pi / 4)\n",
    "\n",
    "center = torch.tensor([0.5, 0.5])\n",
    "rotation_matrix = torch.tensor([[ torch.cos(theta), torch.sin(theta)],\n",
    "                                [-torch.sin(theta), torch.cos(theta)]])\n",
    "\n",
    "constrained_relative_coordinates = torch.matmul(mu[constrained_indices] - center, rotation_matrix.T) + center\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff105a3-0ef7-4610-84be-c2b92b6e32ea",
   "metadata": {},
   "source": [
    "# The Analytical Score Model\n",
    "\n",
    "We will not train a learnable score model. Here, in the interest of time, we will use an analytical model that creates the score\n",
    "exactly. This is not available in general: it can be computed for this idealized situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c778638ea3b81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_for_multi_scale_molecular_dynamics.models.score_networks.analytical_score_network import \\\n",
    "    AnalyticalScoreNetworkParameters, AnalyticalScoreNetwork\n",
    "\n",
    "score_network_parameters = AnalyticalScoreNetworkParameters(number_of_atoms=number_of_atoms,\n",
    "                                                            spatial_dimension=spatial_dimension,\n",
    "                                                            num_atom_types=1,\n",
    "                                                            kmax=4,\n",
    "                                                            equilibrium_relative_coordinates=equilibrium_relative_coordinates,\n",
    "                                                            sigma_d=sigma_d)\n",
    "\n",
    "axl_network = AnalyticalScoreNetwork(score_network_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915454e728cfc38d",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "We can draw samples with the analytical score network. In order to do so, we create a \"generator\" which is responsible for\n",
    "creating new samples by using the analytical axl_network to denoise random starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfe5693b2ae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_for_multi_scale_molecular_dynamics.generators.sampling_constraint import SamplingConstraint\n",
    "from diffusion_for_multi_scale_molecular_dynamics.generators.constrained_langevin_generator import \\\n",
    "    ConstrainedLangevinGenerator\n",
    "from diffusion_for_multi_scale_molecular_dynamics.sampling.diffusion_sampling import create_batch_of_samples\n",
    "import torch\n",
    "from diffusion_for_multi_scale_molecular_dynamics.generators.predictor_corrector_axl_generator import \\\n",
    "    PredictorCorrectorSamplingParameters\n",
    "from diffusion_for_multi_scale_molecular_dynamics.generators.langevin_generator import LangevinGenerator\n",
    "\n",
    "\n",
    "# We must define the parameters of this noising process.\n",
    "noise_parameters = NoiseParameters(total_time_steps=25,\n",
    "                                   schedule_type=\"exponential\",\n",
    "                                   sigma_min=0.001,\n",
    "                                   sigma_max=0.2)\n",
    "\n",
    "\n",
    "# Sampling parameters\n",
    "cell_dimensions = [1.0, 1.0]\n",
    "\n",
    "# Define the sampling parameters. We will draw a single sample, and we will record the corresponding trajectory during \n",
    "# diffusion to see what it looks like.\n",
    "sampling_parameters = PredictorCorrectorSamplingParameters(number_of_samples=1,\n",
    "                                                           spatial_dimension=spatial_dimension,\n",
    "                                                           number_of_corrector_steps=1,\n",
    "                                                           num_atom_types=1,\n",
    "                                                           number_of_atoms=number_of_atoms,\n",
    "                                                           use_fixed_lattice_parameters=True,\n",
    "                                                           cell_dimensions=cell_dimensions,\n",
    "                                                           record_samples=True)\n",
    "\n",
    "# Define an unconstrained generator. This should generate samples from the effective dataset distribution.\n",
    "generator = LangevinGenerator(noise_parameters=noise_parameters,\n",
    "                              sampling_parameters=sampling_parameters,\n",
    "                              axl_network=axl_network)\n",
    "\n",
    "# Define a constrained generator. We specify the \"constrained indices\" because the model is not equivariant. \n",
    "# An equivariant model wouldn't \"need to know\" which index are constrained...\n",
    "sampling_constraint = SamplingConstraint(elements=elements,\n",
    "                                         constrained_relative_coordinates=constrained_relative_coordinates,\n",
    "                                         constrained_atom_types=torch.zeros_like(constrained_indices),\n",
    "                                         constrained_indices=constrained_indices)\n",
    "\n",
    "constrained_generator = ConstrainedLangevinGenerator(noise_parameters=noise_parameters,\n",
    "                                                     sampling_parameters=sampling_parameters,\n",
    "                                                     axl_network=axl_network,\n",
    "                                                     sampling_constraints=sampling_constraint)\n",
    "\n",
    "# Draw samples, both free and constrained.\n",
    "with torch.no_grad():\n",
    "    device = torch.device('cpu')\n",
    "    samples_batch = create_batch_of_samples(generator=generator,\n",
    "                                            sampling_parameters=sampling_parameters,\n",
    "                                            device=device)\n",
    "\n",
    "    constrained_samples_batch = create_batch_of_samples(generator=constrained_generator,\n",
    "                                                        sampling_parameters=sampling_parameters,\n",
    "                                                        device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95b1be300e0bde",
   "metadata": {},
   "source": [
    "# Visualizing Trajectories\n",
    "\n",
    "We can can gauge the quality of the samples by looking at videos of the sampling trajectories.\n",
    "\n",
    "The videos show a representation of the effective datasets in terms of isosurfaces (concentric blue circles) as well as the evolving\n",
    "sample relative coordinates as time goes from 1 (fully noised configuration) to 0 (the \"data space\").\n",
    "\n",
    "The \"free sample\" aim to look like the effective dataset, wheras the \"constrained sample\" has atoms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf0eb3ca2082af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import create_2d_trajectory_video\n",
    "import einops\n",
    "from diffusion_for_multi_scale_molecular_dynamics import TOP_DIR\n",
    "\n",
    "list_generators = [generator, constrained_generator]\n",
    "list_output_filenames = [\"free_trajectory_video.mp4\", \"constrained_trajectory_video.mp4\"]\n",
    "\n",
    "for gen, output_filename in zip(list_generators, list_output_filenames):\n",
    "    # The trajectory is held internally in the trajectory recorder object\n",
    "    list_x = []\n",
    "    for step_dictionary in gen.sample_trajectory_recorder._internal_data['predictor_step']:\n",
    "        list_x.append(step_dictionary['composition_im1'].X)\n",
    "\n",
    "    trajectories = einops.rearrange(list_x, \"time batch natoms d -> batch time natoms d\")\n",
    "\n",
    "    trajectory = trajectories[0]\n",
    "    video_output_path = output_path / output_filename\n",
    "    create_2d_trajectory_video(trajectory, mu, constrained_relative_coordinates, sigma_d, video_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bae876e49e8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "free_trajectory_video = str(output_path  / \"free_trajectory_video.mp4\")\n",
    "constrained_trajectory_video = str(output_path  / \"constrained_trajectory_video.mp4\")\n",
    "\n",
    "# We can now visualize what the diffusion trajectories look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa846843afaf2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For free diffusion\n",
    "Video(free_trajectory_video, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9ec27-96e9-4503-aad0-3e0ea5cc03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For constrained diffusion\n",
    "Video(constrained_trajectory_video, embed=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
